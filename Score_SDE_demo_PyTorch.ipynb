{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Score SDE demo PyTorch",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true,
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/yang-song/score_sde_pytorch/blob/main/Score_SDE_demo_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBJappt3toqj"
   },
   "source": [
    "# Preparation\n",
    "\n",
    "1. `git clone https://github.com/yang-song/score_sde_pytorch.git`\n",
    "\n",
    "2. Install [required packages](https://github.com/yang-song/score_sde_pytorch/blob/main/requirements.txt)\n",
    "\n",
    "3. `cd` into folder `score_sde_pytorch`, launch a local jupyter server and connect to colab following [these instructions](https://research.google.com/colaboratory/local-runtimes.html)\n",
    "\n",
    "4. Download pre-trained [checkpoints](https://drive.google.com/drive/folders/1tFmF_uh57O6lx9ggtZT_5LdonVK2cV-e?usp=sharing) and save them in the `exp` folder."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qa9OIcJmUKmZ",
    "cellView": "form",
    "outputId": "8fde468b-2c95-4003-f0bd-20ddad5248e7"
   },
   "source": [
    "#@title Autoload all modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import importlib\n",
    "import os\n",
    "import functools\n",
    "import itertools\n",
    "import torch\n",
    "from losses import get_optimizer\n",
    "from models.ema import ExponentialMovingAverage\n",
    "\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_gan as tfgan\n",
    "import tqdm\n",
    "import io\n",
    "import likelihood\n",
    "import controllable_generation\n",
    "from utils import restore_checkpoint\n",
    "sns.set(font_scale=2)\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "import models\n",
    "from models import utils as mutils\n",
    "from models import ncsnv2\n",
    "from models import ncsnpp\n",
    "from models import ddpm as ddpm_model\n",
    "from models import layerspp\n",
    "from models import layers\n",
    "from models import normalization\n",
    "import sampling\n",
    "from likelihood import get_likelihood_fn\n",
    "from sde_lib import VESDE, VPSDE, subVPSDE\n",
    "from sampling import (ReverseDiffusionPredictor, \n",
    "                      LangevinCorrector, \n",
    "                      EulerMaruyamaPredictor, \n",
    "                      AncestralSamplingPredictor, \n",
    "                      NoneCorrector, \n",
    "                      NonePredictor,\n",
    "                      AnnealedLangevinDynamics)\n",
    "import datasets"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-reedYgCU79v",
    "cellView": "form"
   },
   "source": [
    "# @title Load the score-based model\n",
    "sde = 'VESDE' #@param ['VESDE', 'VPSDE', 'subVPSDE'] {\"type\": \"string\"}\n",
    "if sde.lower() == 'vesde':\n",
    "  from configs.ve import cifar10_ncsnpp_continuous as configs\n",
    "  ckpt_filename = \"exp/ve/cifar10_ncsnpp_continuous/checkpoint_24.pth\"\n",
    "  config = configs.get_config()  \n",
    "  sde = VESDE(sigma_min=config.model.sigma_min, sigma_max=config.model.sigma_max, N=config.model.num_scales)\n",
    "  sampling_eps = 1e-5\n",
    "elif sde.lower() == 'vpsde':\n",
    "  from configs.vp import cifar10_ddpmpp_continuous as configs  \n",
    "  ckpt_filename = \"exp/vp/cifar10_ddpmpp_continuous/checkpoint_8.pth\"\n",
    "  config = configs.get_config()\n",
    "  sde = VPSDE(beta_min=config.model.beta_min, beta_max=config.model.beta_max, N=config.model.num_scales)\n",
    "  sampling_eps = 1e-3\n",
    "elif sde.lower() == 'subvpsde':\n",
    "  from configs.subvp import cifar10_ddpmpp_continuous as configs\n",
    "  ckpt_filename = \"exp/subvp/cifar10_ddpmpp_continuous/checkpoint_26.pth\"\n",
    "  config = configs.get_config()\n",
    "  sde = subVPSDE(beta_min=config.model.beta_min, beta_max=config.model.beta_max, N=config.model.num_scales)\n",
    "  sampling_eps = 1e-3\n",
    "\n",
    "batch_size =   64#@param {\"type\":\"integer\"}\n",
    "config.training.batch_size = batch_size\n",
    "config.eval.batch_size = batch_size\n",
    "\n",
    "random_seed = 0 #@param {\"type\": \"integer\"}\n",
    "\n",
    "sigmas = mutils.get_sigmas(config)\n",
    "scaler = datasets.get_data_scaler(config)\n",
    "inverse_scaler = datasets.get_data_inverse_scaler(config)\n",
    "score_model = mutils.create_model(config)\n",
    "\n",
    "optimizer = get_optimizer(config, score_model.parameters())\n",
    "ema = ExponentialMovingAverage(score_model.parameters(),\n",
    "                               decay=config.model.ema_rate)\n",
    "state = dict(step=0, optimizer=optimizer,\n",
    "             model=score_model, ema=ema)\n",
    "\n",
    "state = restore_checkpoint(ckpt_filename, state, config.device)\n",
    "ema.copy_to(score_model.parameters())"
   ],
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "G8ei2Xsfg6JQ",
    "cellView": "form"
   },
   "source": [
    "#@title Visualization code\n",
    "\n",
    "def image_grid(x):\n",
    "  size = config.data.image_size\n",
    "  channels = config.data.num_channels\n",
    "  img = x.reshape(-1, size, size, channels)\n",
    "  w = int(np.sqrt(img.shape[0]))\n",
    "  img = img.reshape((w, w, size, size, channels)).transpose((0, 2, 1, 3, 4)).reshape((w * size, w * size, channels))\n",
    "  return img\n",
    "\n",
    "def show_samples(x):\n",
    "  x = x.permute(0, 2, 3, 1).detach().cpu().numpy()\n",
    "  img = image_grid(x)\n",
    "  plt.figure(figsize=(8,8))\n",
    "  plt.axis('off')\n",
    "  plt.imshow(img)\n",
    "  plt.show()\n"
   ],
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hbBGjCMNUsp"
   },
   "source": [
    "# Predictor Corrector sampling\n",
    "\n",
    "\n",
    "Recommended settings:\n",
    "\n",
    " | dataset | SDE | predictor | corrector | snr | n_steps |\n",
    "|:----:|:----:|:----------:|:--------:|:---:|:----:|\n",
    "|CIFAR-10 | VE | ReverseDiffusionPredictor | LangevinCorrector | 0.16| 1|\n",
    "|CIFAR-10 | VP | EulerMaruyamaPredictor | None | - | - |\n",
    "|CIFAR-10 | subVP| EulerMaruyamaPredictor | None | - | - |\n",
    "| LSUN/CelebA-HQ/FFHQ 256px | VE | ReverseDiffusionPredictor | LangevinCorrector | 0.075 | 1 |\n",
    "| FFHQ 1024px | VE | ReverseDiffusionPredictor | LangevinCorrector | 0.15| 1 |\n",
    "\n",
    "Check `probability_flow` to run PC sampling based on discretizing the probability flow ODE."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "_X41BhiLqJvM",
    "cellView": "form",
    "outputId": "8a5b3b5f-93ad-4baf-d66f-0a648f935170"
   },
   "source": [
    "#@title PC sampling\n",
    "img_size = config.data.image_size\n",
    "channels = config.data.num_channels\n",
    "shape = (batch_size, channels, img_size, img_size)\n",
    "predictor = ReverseDiffusionPredictor #@param [\"EulerMaruyamaPredictor\", \"AncestralSamplingPredictor\", \"ReverseDiffusionPredictor\", \"None\"] {\"type\": \"raw\"}\n",
    "corrector = LangevinCorrector #@param [\"LangevinCorrector\", \"AnnealedLangevinDynamics\", \"None\"] {\"type\": \"raw\"}\n",
    "snr = 0.16 #@param {\"type\": \"number\"}\n",
    "n_steps =  1#@param {\"type\": \"integer\"}\n",
    "probability_flow = False #@param {\"type\": \"boolean\"}\n",
    "sampling_fn = sampling.get_pc_sampler(sde, shape, predictor, corrector,\n",
    "                                      inverse_scaler, snr, n_steps=n_steps,\n",
    "                                      probability_flow=probability_flow,\n",
    "                                      continuous=config.training.continuous,\n",
    "                                      eps=sampling_eps, device=config.device)\n",
    "\n",
    "x, n = sampling_fn(score_model)\n",
    "show_samples(x)"
   ],
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0AdiQdwN2aFA"
   },
   "source": [
    "# Probability flow ODE\n",
    "\n",
    "With black-box ODE solvers, we can produce samples, compute likelihoods, and obtain a uniquely identifiable encoding of any data point."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "iLQDfFvHSIGn",
    "cellView": "form",
    "outputId": "f1888e8b-4e70-446d-d248-9f1c1b6a7916"
   },
   "source": [
    " #@title ODE sampling\n",
    "\n",
    "shape = (batch_size, 3, 32, 32)\n",
    "sampling_fn = sampling.get_ode_sampler(sde,                                        \n",
    "                                       shape, \n",
    "                                       inverse_scaler,                                       \n",
    "                                       denoise=True, \n",
    "                                       eps=sampling_eps,\n",
    "                                       device=config.device)\n",
    "x, nfe = sampling_fn(score_model)\n",
    "show_samples(x)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MsdcLnhu7s46",
    "cellView": "form"
   },
   "source": [
    "#@title Likelihood computation\n",
    "train_ds, eval_ds, _ = datasets.get_dataset(config, uniform_dequantization=True, evaluation=True)\n",
    "eval_iter = iter(eval_ds)\n",
    "bpds = []\n",
    "likelihood_fn = likelihood.get_likelihood_fn(sde,                                              \n",
    "                                             inverse_scaler,                                             \n",
    "                                             eps=1e-5)\n",
    "for batch in eval_iter:\n",
    "  img = batch['image']._numpy()\n",
    "  img = torch.tensor(img).permute(0, 3, 1, 2).to(config.device)\n",
    "  img = scaler(img)\n",
    "  bpd, z, nfe = likelihood_fn(score_model, img)\n",
    "  bpds.extend(bpd)\n",
    "  print(f\"average bpd: {torch.tensor(bpds).mean().item()}, NFE: {nfe}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "id": "oe3rLGRm28nc",
    "cellView": "form",
    "outputId": "4d3b614b-df5b-4523-aa91-a223d6134397"
   },
   "source": [
    "#@title Representations\n",
    "train_ds, eval_ds, _ = datasets.get_dataset(config, uniform_dequantization=False, evaluation=True)\n",
    "eval_batch = next(iter(eval_ds))\n",
    "eval_images = eval_batch['image']._numpy()\n",
    "shape = (batch_size, 3, 32, 32)\n",
    "\n",
    "likelihood_fn = likelihood.get_likelihood_fn(sde, inverse_scaler, eps=1e-5)\n",
    "sampling_fn = sampling.get_ode_sampler(sde, shape, inverse_scaler,\n",
    "                                       denoise=True, eps=sampling_eps, device=config.device)\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.axis('off')\n",
    "plt.imshow(image_grid(eval_images))\n",
    "plt.title('Original images')\n",
    "\n",
    "eval_images = torch.from_numpy(eval_images).permute(0, 3, 1, 2).to(config.device)\n",
    "_, latent_z, _ = likelihood_fn(score_model, scaler(eval_images))\n",
    "\n",
    "x, nfe = sampling_fn(score_model, latent_z)\n",
    "\n",
    "x = x.permute(0, 2, 3, 1).cpu().numpy()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.axis('off')\n",
    "plt.imshow(image_grid(x))\n",
    "plt.title('Reconstructed images')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kaGYVD7KcoW6"
   },
   "source": [
    "# Controllable generation\n",
    "\n",
    "Several demonstrations on how to solve inverse problems with our SDE framework.\n",
    "\n",
    "Recommended settings\n",
    "\n",
    "| dataset | SDE | predictor | corrector | snr | n_steps |\n",
    "|:----:|:----:|:----------:|:--------:|:---:|:----:|\n",
    "|CIFAR-10 | VE | ReverseDiffusionPredictor | LangevinCorrector | 0.16| 1|\n",
    "|CIFAR-10 | VP | EulerMaruyamaPredictor | None | - | - |\n",
    "|CIFAR-10 | subVP| EulerMaruyamaPredictor | None | - | - |\n",
    "| LSUN/CelebA-HQ/FFHQ 256px | VE | ReverseDiffusionPredictor | LangevinCorrector | 0.075 | 1 |\n",
    "| FFHQ 1024px | VE | ReverseDiffusionPredictor | LangevinCorrector | 0.15| 1 |"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "tbly_8RIjqJD",
    "cellView": "form",
    "outputId": "28ca290e-1079-4031-e37a-c69374398f76"
   },
   "source": [
    "#@title PC inpainting\n",
    "train_ds, eval_ds, _ = datasets.get_dataset(config)\n",
    "eval_iter = iter(eval_ds)\n",
    "bpds = []\n",
    "\n",
    "predictor = ReverseDiffusionPredictor #@param [\"EulerMaruyamaPredictor\", \"AncestralSamplingPredictor\", \"ReverseDiffusionPredictor\", \"None\"] {\"type\": \"raw\"}\n",
    "corrector = LangevinCorrector #@param [\"LangevinCorrector\", \"AnnealedLangevinDynamics\", \"None\"] {\"type\": \"raw\"}\n",
    "snr = 0.16 #@param {\"type\": \"number\"}\n",
    "n_steps = 1 #@param {\"type\": \"integer\"}\n",
    "probability_flow = False #@param {\"type\": \"boolean\"}\n",
    "\n",
    "pc_inpainter = controllable_generation.get_pc_inpainter(sde,\n",
    "                                                        predictor, corrector,\n",
    "                                                        inverse_scaler,\n",
    "                                                        snr=snr,\n",
    "                                                        n_steps=n_steps,\n",
    "                                                        probability_flow=probability_flow,\n",
    "                                                        continuous=config.training.continuous,\n",
    "                                                        denoise=True)\n",
    "batch = next(eval_iter)\n",
    "img = batch['image']._numpy()\n",
    "img = torch.from_numpy(img).permute(0, 3, 1, 2).to(config.device)\n",
    "show_samples(img)\n",
    "\n",
    "mask = torch.ones_like(img)\n",
    "mask[:, :, :, 16:] = 0.\n",
    "show_samples(img * mask)\n",
    "\n",
    "\n",
    "x = pc_inpainter(score_model, scaler(img), mask)\n",
    "show_samples(x)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DsP-ayb8cupk",
    "cellView": "form",
    "outputId": "51272ecd-4ba3-4931-8a6d-358c6218e25b"
   },
   "source": [
    "#@title PC colorizer\n",
    "train_ds, eval_ds, _ = datasets.get_dataset(config)\n",
    "eval_iter = iter(eval_ds)\n",
    "bpds = []\n",
    "\n",
    "predictor = ReverseDiffusionPredictor #@param [\"EulerMaruyamaPredictor\", \"AncestralSamplingPredictor\", \"ReverseDiffusionPredictor\", \"None\"] {\"type\": \"raw\"}\n",
    "corrector = LangevinCorrector #@param [\"LangevinCorrector\", \"AnnealedLangevinDynamics\", \"None\"] {\"type\": \"raw\"}\n",
    "snr = 0.16 #@param {\"type\": \"number\"}\n",
    "n_steps = 1 #@param {\"type\": \"integer\"}\n",
    "probability_flow = False #@param {\"type\": \"boolean\"}\n",
    "\n",
    "batch = next(eval_iter)\n",
    "img = batch['image']._numpy()\n",
    "img = torch.from_numpy(img).permute(0, 3, 1, 2).to(config.device)\n",
    "show_samples(img)\n",
    "gray_scale_img = torch.mean(img, dim=1, keepdims=True).repeat(1, 3, 1, 1)\n",
    "show_samples(gray_scale_img)\n",
    "gray_scale_img = scaler(gray_scale_img)\n",
    "pc_colorizer = controllable_generation.get_pc_colorizer(\n",
    "    sde, predictor, corrector, inverse_scaler,\n",
    "    snr=snr, n_steps=n_steps, probability_flow=probability_flow,\n",
    "    continuous=config.training.continuous, denoise=True\n",
    ")\n",
    "x = pc_colorizer(score_model, gray_scale_img)\n",
    "\n",
    "show_samples(x)"
   ],
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HiYRNB-Wk329"
   },
   "source": [
    "## Class-conditional generation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTu-5e6S68Gb"
   },
   "source": [
    "Check out the [class-conditional generation section](https://colab.research.google.com/drive/1dRR_0gNRmfLtPavX2APzUggBuXyjWW55#scrollTo=HiYRNB-Wk329&line=3&uniqifier=1) in our [JAX demo](https://colab.research.google.com/drive/1dRR_0gNRmfLtPavX2APzUggBuXyjWW55?usp=sharing)"
   ]
  }
 ]
}
